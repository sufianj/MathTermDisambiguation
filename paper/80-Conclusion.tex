\squeezeup
\section{Conclusion and Future Works}
~\label{sec:conclusion}
This work introduces a new dataset for %fine-grained
mathematical term disambiguation with ProofWiki. Two entity linking approaches have been implemented and shown to yield advantages in the usage of contextualized embeddings to differentiate mathematical definitions. The experimental results proved the efficiency and effectiveness of using out-of-the-box SBERT. %This work indicates the need for further study on finetuning general purpose pretrained models for new domains and tasks. %not conventionally considered ideal for transfer learning.
%This work opens up future research on building sentence embeddings while benefiting from domain-specific MLM and task-related pretraining.} 
Further work is planned on applying the proposed approaches on scholarly papers. In addition, the current approach is to be extended to include document-level representation and citation information to differentiate definitions in scholarly papers. This work also indicates the need for further study on building sentence transformers that benefit from domain-specific MLM and task-related pretraining.

%For future work, we will apply the study to scholarly papers and not just ProofWiki
%, especially text extracted from PDF articles because the LaTeX source is not always available
%We also plan to combine sentence representation with document-level representation and citation information to differentiate definitions in scholarly papers. 